#+TITLE: Personal Blog
#+AUTHOR: Ryan Cummings

# How to use:
# Add a new heading as a todo
# Set property EXPORT_FILE_NAME (C-c C-x p) to a unique name
# Write post
# Change state to DONE
# Commit changes to GitHub

#+HUGO_BASE_DIR: ./
#+HUGO_AUTO_SET_LASTMOD: t

* Pages
:PROPERTIES:
:EXPORT_HUGO_SECTION: pages
:EXPORT_HUGO_WEIGHT: auto
:END:
** About
:PROPERTIES:
:EXPORT_FILE_NAME: about
:END:
#+attr_html: :width 400
[[file:static/img/site/profile.jpg][file:/img/site/profile.jpg]]
*** Welcome!
I'm Ryan and this is my website. I am a medical student specializing in radiology, hoping to one day shape the future of medicine through artificial intelligence. In the meantime, I have a lot to figure out and even more to write about, and started this blog to catch the overflow.

This blog is unique because it lives in a plain-text file on my computer. The file is nothing special at all really, just a ton of text and a few hyperlinks to images and colors. What turns the blog from a text file into what you see here is a neat program called [[https://github.com/kaushalmodi/ox-hugo][ox-hugo]], which is itself an add-on to an even more incredible piece of software called [[https://www.gnu.org/software/emacs/][GNU Emacs]]. This infinitely-expandable text editor has held every note I took in medical school, every academic paper I've ever written, every todo-list and shopping-list, and basically everything else in my brain for almost 7 years now. Seriously, it's all in Emacs, and I couldn't live without it.

Over the course of this blog, I'll be writing technical guides relevant to Emacs, AI, web development, and anything else I have figured out and want to remember or share. I'll also be writing about medical training, philosophy, cycling, my dog, or any of my other million hobbies. With my goldfish memory, it pays for me to keep tabs on what I'm doing and what I'm thinking about, and this blog will be part of that process. I wouldn't be surprised if it ends up scatter-brained, considering the source material.

So read an article or two and enjoy!

-- Ryan

** Projects
:PROPERTIES:
:EXPORT_FILE_NAME: projects
:END:
As I push new websites to my domain, I'll update them here.
** Links
:PROPERTIES:
:EXPORT_FILE_NAME: links
:END:
Links I like and use frequently will live here.
* Posts
:PROPERTIES:
:EXPORT_HUGO_SECTION: posts
:END:
** Technical                                                        :@technical:
*** DONE my-hugo-screenshot: a simple custom Emacs function :emacs:meta:hugo:
CLOSED: [2020-02-21 Fri 09:40]
:PROPERTIES:
:EXPORT_FILE_NAME: hugo-screenshot-function
:END:
**** Introduction
This blog is written with an endlessly customizable text editor called [[https://www.gnu.org/software/emacs/][Emacs]]. It is deployed using an Emacs customization called [[https://github.com/kaushalmodi/ox-hugo][Ox-Hugo]], which exports so-called [[https://orgmode.org/][org-mode]] files into markdown format for the Hugo static website generator. The static site is pushed to Github for version control and automatically deployed to my domain with a free service offered by Netlify.

There are a lot of different ways to write a blog. Platforms like [[https://www.wordpress.com][WordPress]] and [[https://www.blogger.com/][Blogger]] have been around for ages, and I've used quite a few of them. These platforms are excellent, there's no doubt about that. So why go through the trouble of rolling your own blog with Emacs?

In this post, I'll walk through a function I just wrote to instantly add screenshots to posts. That's one beautiful thing about Emacs -- you can literally program your text editor on-the-fly. I realized that adding screenshots was taking up too much time, so I spent 10 minutes writing a function that made it better. How awesome is that?

**** TLDR: The function
#+begin_src lisp
(defun my-hugo-screenshot (name)
  "Take a screenshot into a time stamped unique-named file with suffix NAME and paste link at point."
  (interactive "sEnter a screenshot name: ")
  (setq imagename (concat (format-time-string "%Y%m%d_%H%M%S")
                          "_" name ".png"))
  (setq filename (concat "~/org/blog/static/img/screenshots/"
                         imagename))
  (setq filelink (concat "/img/screenshots/" imagename))
  (message "waiting 5 seconds while you open the right window")
  (sit-for 5)
  (shell-command (concat "import " filename))
  (insert (concat "[[" filelink "]]")))

(global-set-key "\C-cs" 'my-hugo-screenshot)
#+end_src
**** Commentary
I won't sugar-coat it. This is an ugly function. Lines are poorly wrapped, too many variables are used, and there is no error checking at all. But it works flawlessly, and it took 10 minutes to research and write. That's all. From start to finish, finding a shell command to take a screenshot on my Linux laptop and writing this little code to take the screenshot, copy it to the static images folder, and add a link in the blog post, took 10 minutes.

For the uninitiated, Emacs is written in a variant of the Lisp programming language ([[https://en.wikipedia.org/wiki/Lisp_(programming_language)][-> Wikipedia]]) called elisp. Lisp is a beautiful but rarely-used language characterized by all of those parentheses. The language is worth exploring if you have some free time. I believe that every programmer should learn 3 different languages, no matter what their goals are, and learning Lisp will absolutely teach you something about computer science. That said, I have barely scratched the surface, hence the horribly messy function.

On my Arch Linux machine, the command "import" calls an ImageMagick utility that lets you either define a boundary to screenshot, or click on a window to screenshot. The following code tells Emacs to run the command in the shell:
#+begin_src lisp
(shell-command (concat "import " filename))
#+end_src
The ~filename~ variable is generated pragmatically based on the user's input when the function is first called (using the ~interactive~ prompt), and the date and time. The link to the screenshot file needs to be relative to the blog file's directory, hence the extra code generating ~filelink~. And the ~global-set-key~ function at the end links the function with the unused key shortcut Ctrl-c s. The whole function lives in my Emacs init file, which loads every time Emacs opens. A detailed explanation of my /init/ is a job for another day.

And that's it! The screenshot is saved in the blog's static screenshots folder and a link is placed in the document. Look, I'll screenshot my writing environment right now:

[[/img/screenshots/20200221_093645_sample_screenshot.png]]

Let's see WordPress beat that.

Emacs is an incredible piece of software and it makes writing this blog a pleasure. I hope this little example is helpful to someone thinking about trying Emacs or writing basic functions and extensions for it. Learning Emacs can be a long road, but for so many reasons, I can't imagine my life without this software, and that is a unique thing.
*** DONE Hugo theming basics: how to change the width of a page :meta:hugo:
CLOSED: [2020-02-24 Mon 12:34]
:PROPERTIES:
:EXPORT_FILE_NAME: hugo-width-adjustment
:END:
**** Introduction
When I first started writing this blog, I opted for a theme called [[https://themes.gohugo.io/hyde-hyde/][hyde-hyde]], based on the Hyde theme for Jekyll. The theme is lovely, with a great two-column interface and the ability to rearrange itself when displayed on mobile devices. However, from the very beginning, I was annoyed that content was rendering very narrow, rather than expanding to fill the width of the page. Here's a screenshot of how it used to look:

[[/img/screenshots/20200224_120806_narrow-content-demo.png]]

And here it is now:

[[/img/screenshots/20200224_120945_content-regular-width.png]]

How did I accomplish this? Read on, dear reader.
**** The Steps
The following steps are for the Hyde-Hyde theme specifically, but should apply just as well to any theme.
***** 1) Fork the theme repo
This was a critical step for a newbie to Git like me. The general Git structure of a Hugo blog is a master repository for the blog content, with a submodule that holds the theme. Most Hugo themes have installation instructions for installing them as submodules. If you plan to make any changes to the blog, you have to *fork* the theme *first* before you install it as a submodule. Basically, forking the theme lets you make and commit changes to your own personal copy of the theme, without messing up the original theme you copied from.
***** 2) Add the forked repo as a submodule
Adding a repo as a submodule is as simple as navigating to your blog's themes directory and running the following:

#+BEGIN_SRC bash
git submodule add *https-route-to-your-forked-repo*
#+END_SRC

Using https to add your forked repo is not strictly necessary if you have SSH set up on GitHub. But, as I found out the hard way, it is *absolutely* necessary if you need Netlify. This is because Netlify clones all submodules when it builds your website from GitHub, and it can only talk to GitHub via https.

****** Deleting a submodule
By the way, if you ever mess up and need to delete a submodule, here are some instructions:
To remove a submodule you need to:

1. Delete the relevant section from the .gitmodules file.
2. Stage the .gitmodules changes git add .gitmodules
3. Delete the relevant section from .git/config.
4. Run ~git rm --cached path_to_submodule~ (no trailing slash).
5. Run ~rm -rf .git/modules/path_to_submodule~ (no trailing slash).
6. Commit ~git commit -m "Removed submodule "~
7. Delete the now untracked submodule files ~rm -rf path_to_submodule~

The instructions are from a post on GitHub [[https://gist.github.com/myusuf3/7f645819ded92bda6677][here]]. I had to do this an embarrassing number of times while figuring this thing out.
***** 3) Find the variable of interest
It took me a lot of trial and error to figure out what variable was controlling the width of my content, but I eventually tracked it down to the following:

File: ~themes/hyde-hyde/assets/scss/hyde-hyde/_variables.scss~

Variable: ~$content-max-width: 32rem~

Changing this to something like ~60rem~ was all it took. When I pushed the change to GitHub and the page reloaded, the width was fixed.

SCSS is completely new to me, but from what I gather, SCSS files are processed to programatically generate CSS. That's why the variable that controlled width was in a special ~_variables~ file rather than in a CSS file. Changing the content-max-width variable anywhere else in the structure has no effect on the output CSS; only changes in the ~_variables~ file make a difference in the final output.
***** 4) Commit and push your submodule and main git repo
At this point, you can commit all changes and push them up to GitHub. In a minute, Netlify should pick up the changes and your website should render with beautiful 60-rem-wide content. Tada!
*** DONE Jupyter notebooks over SSH for remote deep learning on a GPU :python:ai:
CLOSED: [2020-02-28 Fri 20:09]
:PROPERTIES:
:EXPORT_FILE_NAME: jupyter_ssh
:END:
#+attr_html: :width 200
[[/img/misc/jupyter_logo.png][file:/img/misc/jupyter_logo.png]]
I love [[https://jupyter.org/][Jupyter]] notebooks. As someone who primarily works on data science projects in Python, Jupyter is probably the most important tool in my toolchain. For the uninitiated, Jupyter notebooks are documents that can contain live code, visualizations, and descriptive text. By breaking code into chunks, Jupyter notebooks let you run your code in a non-linear way, jumping from block to block and letting Jupyter keep track of variables and environment. Rather than writing a python file and then running the whole thing, Jupyter lets you add in print() statements and visualization commands half-way through the execution of your code easy.

Youtuber Corey Schafer has an amazing breakdown, shown below:

#+begin_export html
<iframe width="925" height="529" src="https://www.youtube.com/embed/HW29067qVWk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
#+end_export
**** Remote access to notebook
I use Jupyter for deep machine learning, taking advantage of a gaming pc with a gpu. This pc runs Ubuntu linux (and dual-boots Windows for actual gaming) and is accessible over my network by SSH. It is possible to work on this computer, but I would much rather work remotely from my laptop and external monitor.

To accomplish this task, I created the following shell script:
#+BEGIN_SRC shell
#!/bin/bash
#title           : Jupyter connection
#description     : Connect to jupyter notebook
#author          : Ryan Cummings
#date            : 20190229

ssh -o StrictHostKeyChecking=no gamer "source ~/anaconda3/etc/profile.d/conda.sh; conda activate pytorch; jupyter notebook --no-browser --port=8887" &
urxvt -e sh -c "ssh -N -L localhost:8888:localhost:8887 USERNAME@gamer"
#+END_SRC

This very simple script does two things. The first command logs into my gaming pc via SSH using the "gamer" profile I set up elsewhere in my ~.ssh/config~ file. It then activates my Anaconda virtual python environment, which is necessary to run the jupyter notebook. Lastly, it runs ~jupyter notebook~ on port 8887 with no browser.

The second command (which opens without waiting for the first to finish, because of the ~&~ symbol) opens a new urxvt terminal window and opens a tunnel to my gaming pc. The tunnel links my laptop's port 8888 with the gaming pc's port 8887, where the jupyter notebook is running. The terminal will look blank, but the port should be ready.

Now, all you have to do is click the url provided in the first terminal window where the jupyter notebook is running. A web browser window will open pointing to localhost:8887/LONG_TOKEN_TEXT. Change the 7 to an 8 and you will login to the notebook with the token in the long URL. And that's it! Any code you run will run on the remote notebook server, and you can use the GPU to your heart's content.

It took me a little while to figure this out. I hope it helps out another data scientist in need!
*** DONE Making a basic Reddit market scraper with Python          :python:
CLOSED: [2020-03-31 Tue 17:51]
:PROPERTIES:
:EXPORT_FILE_NAME: reddit_scraper_v1
:END:
A few weeks ago, BestBuy mistakenly listed a high quality 2tb SSD for more than $200 under retail price. The mistake only lasted a few minutes, but the lucky few who saw it in time got an amazing deal. I found out about the deal through [[https://www.reddit.com/r/buildapcsales/][the BuildAPcSales subreddit]]. But I have better things to do than prowl reddit for deals on tech. My secret weapon? A python script that searches Reddit for things I want to buy, and notifies me via phone if a deal pops up. 

In this post, I'll describe my Reddit market watcher script and help you build your own. Let's getT started!
**** First steps - setting up the environment
It's always a good idea to write a Python program using a virtual environment. To do so, make a new folder where your script will live and execute the following from your shell. 

#+BEGIN_SRC bash
python3 -m venv reddit_venv ./reddit_venv
#+END_SRC

Now that you have a virtual environment sitting inside your project folder, activate the venv using the command:

#+BEGIN_SRC bash
source ./reddit_venv/bin/activate
#+END_SRC

Depending on your shell, you may find that the name of the virtual environment is now listed in the shell prompt. Now that you are using your virtual environment, you need to run the ~praw~ python library to use the Reddit API:

#+BEGIN_SRC bash
pip install praw
#+END_SRC

The ~praw~ library documentation is available online [[https://praw.readthedocs.io/en/latest/][here]]. This library has a lot to offer outside the scope of this tutorial, so check it out!
**** Reddit setup
To use the ~praw~ library, you need to register a Reddit API app. Praw offers [[https://praw.readthedocs.io/en/latest/getting_started/quick_start.html][quick start instructions]] to help you out. [[https://github.com/reddit-archive/reddit/wiki/OAuth2-Quick-Start-Example#first-steps][Go here]] for instructions from Reddit on making and registering a Reddit app. You will need the following to make full use of the Reddit API:
- client id
- client secret key
- user agent (app name)
- username (your reddit username)
- password (your reddit password)

**** Database setup
Once you have the login information for your reddit app, you are ready to start coding! First we will import our libraries:
#+BEGIN_SRC python
import praw
import datetime as dt
import requests
import json

import sqlite3
import os
#+END_SRC

Next, let's create a database to store Reddit posts that we download with the API:
#+BEGIN_SRC python
if not os.path.exists('/home/pi/python/reddit.db'):
    conn = sqlite3.connect('/home/pi/python/reddit.db')
    c = conn.cursor()
    with conn:
        c.execute("""CREATE TABLE reddit (
        id text,
        subreddit text,
        title text,
        timestamp text,
        url text
        )""")
else:
    conn = sqlite3.connect('/home/pi/python/reddit.db')
    c = conn.cursor()
#+END_SRC

You will have to customize the paths to point to the project folder you created earlier.

Let's add a few functions that let us work with the database:
#+BEGIN_SRC python
def addEntry(post): # {id, subreddit, title, timestamp, url}
    with conn:
        c.execute("INSERT INTO reddit VALUES (:id, :subreddit, :title, :timestamp, :url)",
                  post)

def isNew(post):
    c.execute("SELECT * FROM reddit WHERE id=:id", {'id': post['id']})
    if c.fetchone():
        return(False)
    else:
        return(True)
#+END_SRC
~addEntry~ creates a new entry from a post dictionary that ~praw~ will give to us later. ~isNew~ will check if a given post dictionary is already in the database based on a Reddit post's id. 

**** More API setup
Next, let's create a praw instance to pull posts from Reddit.

#+BEGIN_SRC python
reddit = praw.Reddit(client_id='your_id',
                     client_secret='your_secret_key',
                     user_agent='your_user_agent',
                     username='your_username',
                     password='your_password')
#+END_SRC

Great. One more custom function will let us use the [[https://www.pushbullet.com/][PushBullet]] service to push notifications to our devices. You'll need a PushBullet token to use the service, so if you don't already have one, go ahead and sign up for one. You can read more in the [[https://docs.pushbullet.com/][PushBullet Docs]]. 

#+BEGIN_SRC python
def pushbullet_link(title, body, url):
    msg = {"type": "note", "title": title, "body": body, "url": url }
    TOKEN = 'o.rNItGF4sNrVuKxqpPXcGs9f0G1Ro3j7r'
    resp = requests.post('https://api.pushbullet.com/v2/pushes',
                         data=json.dumps(msg),
                         headers={'Authorization': 'Bearer ' + TOKEN,
                                  'Content-Type': 'application/json'})
    if resp.status_code != 200:
        raise Exception('Error',resp.status_code)
    else:
        print('Message sent')
#+END_SRC
**** The search function
With that setup out of the way, we just need to create a function to search reddit for the stuff we want to buy! The following function takes the following arguments:
- Subreddit: The subreddit you want to search
- mandatorySearchTerms: Exclude all results that lack these terms in the title
- optionalSearchTerms: If a result contains /any/ of these terms, notify the user. 

#+BEGIN_SRC python
def searchReddit(subreddit, mandatorySearchTerms, optionalSearchTerms):
    newPosts = []
    subreddit_instance = reddit.subreddit(subreddit)

    for submission in subreddit_instance.new(limit=100):
        flag = False
        for term in optionalSearchTerms:
            if term.lower() in submission.title.lower():
                flag = True
        for term in mandatorySearchTerms:
            if term.lower() not in submission.title.lower():
                flag = False

        if flag == True:
            newPosts.append({
                "id": submission.id,
                "subreddit": subreddit,
                "title": submission.title,
                "timestamp": dt.datetime.fromtimestamp(submission.created).strftime("%b %d %H:%M:%S"),
                "url": submission.url
            })

    for post in newPosts:
        if isNew(post):
            addEntry(post)
            pushbullet_link("New post found!", post['title'], post['url'])

#+END_SRC

The function is relatively simple:
1) It asks the subreddit for the 100 most recent posts
2) For each recent post, it checks to see if it includes all ~mandatorySearchTerms~ and at least one of the ~optionalSearchTerms~. If it does, it sets a flag to mark the post.
3) Flagged posts are converted to dictionaries containing key information including id, subreddit, title, timestamp, and url. A list of these dictionaries is generated as the program scans all returned posts.
4) The list of flagged posts is cross-referenced with the database. For each post, if it is not in the database, it is added and the user is notified via PushBullet. 
**** A few sample searches
All that remains is using the search function to run a few searches. The following searches the BuildAPcSales subreddit for SSD hard drives:
#+BEGIN_SRC python
searchReddit(subreddit='buildapcsales',
             mandatorySearchTerms=['[SSD]'],
             optionalSearchTerms=['ssd'])

#+END_SRC

And this one searches the Pen_Swap subreddit for my favorite kind of fountain pen, the Vanishing Point:
#+BEGIN_SRC python
searchReddit(subreddit='pen_swap',
             mandatorySearchTerms=['[WTS]'],
             optionalSearchTerms=['vp', 'capless', 'vanishing'])
#+END_SRC
**** Setting up a Cron job
You can manually run the script to see if your searches are working, but someday you will want the script to run automatically. I have a spare Raspberry Pi running my script every two minutes using ~cron~, a tool that lets you execute scripts on unix machines. To set this up, you have to first make a bash scrip that points to your Pyhon script, like this:
#+BEGIN_SRC bash
#!/bin/bash
source /home/pi/python/venv_python/bin/activate
python /home/pi/python/reddit_scraper.py
echo $(date) "Ran Cron job" >> /home/pi/logs/reddit_scraper.log
#+END_SRC

The script should activate your virtual environment, then run the python script. This script also generates a simple log file so I can make sure it's running according to schedule.

Put the script somewhere your bash environment can see it. Follow [[https://mycyberuniverse.com/create-personal-bin-directory-run-scripts-without-specifying-full-path.html][these instructions]] if you need help setting up a personal ~/home/usr/bin~ directory for the script. Make sure the script is executable e.g. ~chmod +x path/to/your/bash_script~. 

Next, just set up a cron job using the command ~crontab -e~. If you need help with setting it up, check out this link: https://linuxize.com/post/scheduling-cron-jobs-with-crontab/. 

All that's left to do is let it run for a while, check your logs, and jump on those sweet deals! Enjoy!

** Academic                                                      :@academic:
*** DONE Step 2 CS Mneumonics                                     :step:cs:
CLOSED: [2020-02-20 Thu 17:25]
:PROPERTIES:
:EXPORT_FILE_NAME: step2cs-mneumonics
:END:
I took Step 2 CS back in October 2019, and (after a very stressful waiting period) found out that I passed with flying colors. The mneumonics below were the best I could find, and memorizing them a few nights before the exam saved me. I had one for peds cases too, but I lost it.
**** Social: TAIMODES:

- Tobacco
- Alcohol
- Illicit drugs
- Married
- Occupation
- Diet
- Exercise
- Sex
- ROS

**** PMH: PAM HITS FOSS

- Past medical
- Allergies
- Meications
- Hospitalizations
- Ill contacts
- Trauma
- Surgical
- Family
- OBGYN
- Sexual
- Social

**** Women's Health: LMP RTV PAP

- LMP
- Menarche
- Periods last?
- Regularity
- Tampons
- Vaginal discharge
- Cramps
- Spotting
- Pregnancy
- Abortions
- Pap smear

**** ROS Hitlist
- Nausea
- Vomiting
- Fever
- Chills
- SOB
- CP
- Changes in hearing/vision
- Changes in bowel/bladder
- Rash or skin changes
- Trauma
- Falls
- Loss of consciousness
- Swelling
- Vaginal discharge
- New numbness, tingling, weakness
- Confusion
- Recent illnesses
- Change in meds
- Pain anywhere else
** Personal                                                      :@personal:
*** DONE new blog who this?                                          :meta:
CLOSED: [2020-02-20 Thu 16:12]
:PROPERTIES:
:EXPORT_FILE_NAME: new-blog-who-this
:END:
**** History...
I had a blog a while ago. It died when I didn't update it and made life more complicated than I had to. The blog was written using a piece of software called Emacs, which is a decades-old text editor. A plugin called ox-hugo converted my Emacs files into markdown files that another piece of software called Hugo converted into a navigable blog. Images were a monster to handle, and I ended up writing some custom code to get them from my computer to the site. The whole thing was hosted on GitHub and linked to a domain that I bought.

It was a mess! It's no wonder that I gave up.

**** ...repeats itself
But now that I am a 4th year medical student, I figure that I'll fire it back up! I love writing and have so many things to write about, from AI and deep learning to medical education to philosophy, not to mention all of the miscelaneous programming projects I've been up to over the past few years. I am also much better at using Git, and feel more confident that this will be more of an active coding project for me (rather than an experiment where I copy-paste interesting code off the internet). This blog may not see any traffic at all (and that may be for the best), but I think it'll be worth having nonetheless.

At least it's fun to write with this setup. Here's my desk:
#+caption: My desk
[[/img/misc/desk.jpg]]
(Yay, images work!)

So welcome to my new blog! Take a look around and check out my social links on the left sidebar. Don't be afraid to email me (the @ link on the sidebar) -- I love getting letters. I hope you get something out of this site.
** Outdoors                                                      :@outdoors:
** Ideas
*** Syncthing overview
*** Publishing with latex in emacs
*** Fast.AI heatmaps
*** Post about reddit scraper
